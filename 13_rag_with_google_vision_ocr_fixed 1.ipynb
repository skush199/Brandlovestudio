{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29fd0c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.11/site-packages (1.2.10)\n",
      "Requirement already satisfied: langchain-openai in ./venv/lib/python3.11/site-packages (1.1.9)\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.11/site-packages (0.4.1)\n",
      "Requirement already satisfied: langgraph in ./venv/lib/python3.11/site-packages (1.0.8)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.11/site-packages (1.13.2)\n",
      "Requirement already satisfied: pypdf in ./venv/lib/python3.11/site-packages (6.7.0)\n",
      "Requirement already satisfied: pdfplumber in ./venv/lib/python3.11/site-packages (0.11.9)\n",
      "Requirement already satisfied: google-cloud-vision in ./venv/lib/python3.11/site-packages (3.12.1)\n",
      "Requirement already satisfied: google-auth in ./venv/lib/python3.11/site-packages (2.48.0)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.11/site-packages (12.1.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in ./venv/lib/python3.11/site-packages (from langchain) (1.2.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.11/site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in ./venv/lib/python3.11/site-packages (from langchain-openai) (2.20.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./venv/lib/python3.11/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in ./venv/lib/python3.11/site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./venv/lib/python3.11/site-packages (from langchain-community) (2.0.46)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in ./venv/lib/python3.11/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in ./venv/lib/python3.11/site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.11/site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.11/site-packages (from langchain-community) (9.1.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./venv/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./venv/lib/python3.11/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in ./venv/lib/python3.11/site-packages (from langchain-community) (0.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.11/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in ./venv/lib/python3.11/site-packages (from langchain-community) (2.4.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in ./venv/lib/python3.11/site-packages (from langgraph) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in ./venv/lib/python3.11/site-packages (from langgraph) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in ./venv/lib/python3.11/site-packages (from langgraph) (0.3.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./venv/lib/python3.11/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from faiss-cpu) (26.0)\n",
      "Requirement already satisfied: pdfminer.six==20251230 in ./venv/lib/python3.11/site-packages (from pdfplumber) (20251230)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in ./venv/lib/python3.11/site-packages (from pdfplumber) (5.4.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./venv/lib/python3.11/site-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./venv/lib/python3.11/site-packages (from pdfminer.six==20251230->pdfplumber) (46.0.5)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in ./venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.29.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./venv/lib/python3.11/site-packages (from google-cloud-vision) (1.78.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./venv/lib/python3.11/site-packages (from google-cloud-vision) (1.27.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in ./venv/lib/python3.11/site-packages (from google-cloud-vision) (6.33.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.11/site-packages (from google-auth) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.11/site-packages (from google-auth) (4.9.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./venv/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./venv/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.72.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.78.0)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in ./venv/lib/python3.11/site-packages (from grpcio<2.0.0,>=1.33.2->google-cloud-vision) (4.15.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in ./venv/lib/python3.11/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.14.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./venv/lib/python3.11/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./venv/lib/python3.11/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./venv/lib/python3.11/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./venv/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (3.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain langchain-openai langchain-community langgraph python-dotenv faiss-cpu pypdf pdfplumber google-cloud-vision google-auth pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9026f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5447034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, START\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f3c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # usses full_text_annotation\n",
    "# import os\n",
    "# import io\n",
    "\n",
    "# import pdfplumber\n",
    "# from google.cloud import vision\n",
    "# from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# class GoogleVisionOCRProcessor:\n",
    "#     def looks_like_cid_encoded(self, text: str) -> bool:\n",
    "#         \"\"\"Detects (cid:XX) patterns indicating CID-encoded garbage.\"\"\"\n",
    "#         return \"(cid:\" in (text or \"\").lower()\n",
    "\n",
    "#     def ocr_image_bytes(self, image_bytes: bytes, client: \"vision.ImageAnnotatorClient\", language_hints=None) -> str:\n",
    "#         \"\"\"Calls Google Vision OCR on image bytes.\"\"\"\n",
    "#         if language_hints is None:\n",
    "#             # Default: Japanese + English (can override per call)\n",
    "#             language_hints = [\"ja\", \"en\"]\n",
    "\n",
    "#         image = vision.Image(content=image_bytes)\n",
    "#         image_context = vision.ImageContext(language_hints=language_hints)\n",
    "#         response = client.document_text_detection(image=image, image_context=image_context)\n",
    "\n",
    "#         if getattr(response, \"error\", None) and response.error.message:\n",
    "#             print(f\"‚ö†Ô∏è Google Vision OCR error: {response.error.message}\")\n",
    "#             return \"\"\n",
    "\n",
    "#         annotation = getattr(response, \"full_text_annotation\", None)\n",
    "#         if annotation and getattr(annotation, \"text\", None):\n",
    "#             return annotation.text.strip()\n",
    "#         return \"\"\n",
    "\n",
    "#     def clamp_bbox_to_page(self, bbox, page_bbox):\n",
    "#         \"\"\"Ensure the bbox is safely inside the page bbox.\"\"\"\n",
    "#         x0, top, x1, bottom = bbox\n",
    "#         page_x0, page_top, page_x1, page_bottom = page_bbox\n",
    "\n",
    "#         x0 = max(page_x0, min(x0, page_x1))\n",
    "#         x1 = max(page_x0, min(x1, page_x1))\n",
    "#         top = max(page_top, min(top, page_bottom))\n",
    "#         bottom = max(page_top, min(bottom, page_bottom))\n",
    "\n",
    "#         if x0 >= x1 or top >= bottom:\n",
    "#             return None\n",
    "#         return (x0, top, x1, bottom)\n",
    "\n",
    "#     def _build_vision_client(self, user_type: str) -> \"vision.ImageAnnotatorClient\":\n",
    "#         \"\"\"Create a Vision client based on user type.\"\"\"\n",
    "#         user_type = (user_type or \"\").strip().lower()\n",
    "\n",
    "#         if user_type == \"org\":\n",
    "#             service_account_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "#             if not service_account_path:\n",
    "#                 raise ValueError(\n",
    "#                     \"GOOGLE_APPLICATION_CREDENTIALS is not set. Put the service account JSON path in your .env or OS env.\"\n",
    "#                 )\n",
    "#             credentials = service_account.Credentials.from_service_account_file(service_account_path)\n",
    "#             print(\"‚úÖ Organization user - using service account from GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "#             return vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "#         if user_type == \"byok\":\n",
    "#             # Uses Application Default Credentials (gcloud auth, metadata server, etc.)\n",
    "#             print(\"‚úÖ BYOK user - using Application Default Credentials for Google Vision\")\n",
    "#             return vision.ImageAnnotatorClient()\n",
    "\n",
    "#         raise ValueError(\"Invalid user_type. Use 'org' or 'byok'.\")\n",
    "\n",
    "#     def extract_text_from_pdf(self, pdf_path: str, user_type: str = \"org\", language_hints=None) -> str:\n",
    "#         \"\"\"Extract text from PDF using text layer + selective OCR, with full-page OCR fallback.\"\"\"\n",
    "#         client = self._build_vision_client(user_type)\n",
    "\n",
    "#         all_pages_text = []\n",
    "#         ocr_pages_count = 0\n",
    "\n",
    "#         with pdfplumber.open(pdf_path) as pdf:\n",
    "#             for i, page in enumerate(pdf.pages):\n",
    "#                 print(f\"\\nüìÑ Processing Page {i + 1}/{len(pdf.pages)}\")\n",
    "#                 parts = []\n",
    "#                 ocr_applied_this_page = False\n",
    "\n",
    "#                 # 1) Try selectable text layer\n",
    "#                 normal_text = (page.extract_text() or \"\").strip()\n",
    "#                 if normal_text and self.looks_like_cid_encoded(normal_text):\n",
    "#                     print(\"‚ö†Ô∏è Detected CID-encoded garbage in text layer. Ignoring text layer.\")\n",
    "#                     normal_text = \"\"\n",
    "\n",
    "#                 has_text_layer = bool(normal_text)\n",
    "#                 if has_text_layer:\n",
    "#                     print(f\"‚úÖ Found valid text layer on page {i + 1}\")\n",
    "#                     parts.append(\"[TEXT LAYER]\\n\" + normal_text)\n",
    "\n",
    "#                     # 2) OCR embedded images only (logos, stamps, scanned snippets)\n",
    "#                     if page.images:\n",
    "#                         print(f\"üîç Found {len(page.images)} image(s) for OCR on page {i + 1}\")\n",
    "#                         ocr_applied_this_page = True\n",
    "\n",
    "#                         page_bbox = (0.0, 0.0, float(page.width), float(page.height))\n",
    "#                         for img_idx, img in enumerate(page.images):\n",
    "#                             try:\n",
    "#                                 raw_bbox = (img[\"x0\"], img[\"top\"], img[\"x1\"], img[\"bottom\"])\n",
    "#                                 safe_bbox = self.clamp_bbox_to_page(raw_bbox, page_bbox)\n",
    "#                                 if not safe_bbox:\n",
    "#                                     print(f\"‚ö†Ô∏è Skipping invalid bbox: {raw_bbox}\")\n",
    "#                                     continue\n",
    "\n",
    "#                                 cropped_img = page.crop(safe_bbox).to_image(resolution=500)\n",
    "#                                 img_bytes = io.BytesIO()\n",
    "#                                 cropped_img.save(img_bytes, format=\"PNG\")\n",
    "\n",
    "#                                 ocr_result = self.ocr_image_bytes(\n",
    "#                                     img_bytes.getvalue(), client, language_hints=language_hints\n",
    "#                                 )\n",
    "#                                 if ocr_result:\n",
    "#                                     parts.append(\"[OCR IMAGE TEXT]\\n\" + ocr_result)\n",
    "#                             except Exception as e:\n",
    "#                                 print(f\"‚ö†Ô∏è Error OCR-ing image #{img_idx + 1} on page {i + 1}: {e}\")\n",
    "\n",
    "#                 else:\n",
    "#                     # 3) If no text layer ‚Üí full-page OCR\n",
    "#                     print(f\"‚ö†Ô∏è No selectable text on page {i + 1}. Performing full-page OCR.\")\n",
    "#                     ocr_applied_this_page = True\n",
    "\n",
    "#                     try:\n",
    "#                         page_image = page.to_image(resolution=500)\n",
    "#                         img_bytes = io.BytesIO()\n",
    "#                         page_image.save(img_bytes, format=\"PNG\")\n",
    "\n",
    "#                         full_page_ocr_result = self.ocr_image_bytes(\n",
    "#                             img_bytes.getvalue(), client, language_hints=language_hints\n",
    "#                         )\n",
    "#                         if full_page_ocr_result:\n",
    "#                             parts.append(\"[FULL PAGE OCR]\\n\" + full_page_ocr_result)\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"‚ö†Ô∏è Error during full-page OCR on page {i + 1}: {e}\")\n",
    "\n",
    "#                 if ocr_applied_this_page:\n",
    "#                     ocr_pages_count += 1\n",
    "\n",
    "#                 combined = \"\\n\\n\".join(parts).strip()\n",
    "#                 if combined:\n",
    "#                     all_pages_text.append(combined)\n",
    "#                 else:\n",
    "#                     print(f\"‚ö†Ô∏è No text found at all on page {i + 1}\")\n",
    "\n",
    "#         print(f\"\\nüìä OCR was applied on {ocr_pages_count} out of {len(pdf.pages)} pages.\")\n",
    "#         print(all_pages_text)\n",
    "#         out_txt = \"ocr_extracted_text.txt\"\n",
    "#         with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "#             for i, page_text in enumerate(all_pages_text, start=1):\n",
    "#                 f.write(f\"\\n\\n===== PAGE {i} =====\\n\\n\")\n",
    "#                 f.write(page_text)\n",
    "\n",
    "#         print(\"‚úÖ Saved to:\", out_txt)\n",
    "#         return \"\\n\\n=== PAGE BREAK ===\\n\\n\".join(all_pages_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4001709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#has all the print block removed so that it does not go into ocr_extracted_text.txt\n",
    "import os\n",
    "import io\n",
    "\n",
    "import pdfplumber\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "class GoogleVisionOCRProcessor:\n",
    "    def looks_like_cid_encoded(self, text: str) -> bool:\n",
    "        \"\"\"Detects (cid:XX) patterns indicating CID-encoded garbage.\"\"\"\n",
    "        return \"(cid:\" in (text or \"\").lower()\n",
    "\n",
    "    def ocr_image_bytes(\n",
    "        self,\n",
    "        image_bytes: bytes,\n",
    "        client: \"vision.ImageAnnotatorClient\",\n",
    "        language_hints=None\n",
    "    ) -> str:\n",
    "        \"\"\"Calls Google Vision OCR on image bytes.\"\"\"\n",
    "        if language_hints is None:\n",
    "            language_hints = [\"ja\", \"en\"]\n",
    "\n",
    "        image = vision.Image(content=image_bytes)\n",
    "        image_context = vision.ImageContext(language_hints=language_hints)\n",
    "        response = client.document_text_detection(image=image, image_context=image_context)\n",
    "\n",
    "        if getattr(response, \"error\", None) and response.error.message:\n",
    "            print(f\"‚ö†Ô∏è Google Vision OCR error: {response.error.message}\")\n",
    "            return \"\"\n",
    "\n",
    "        annotation = getattr(response, \"full_text_annotation\", None)\n",
    "        if annotation and getattr(annotation, \"text\", None):\n",
    "            return annotation.text.strip()\n",
    "        return \"\"\n",
    "\n",
    "    def clamp_bbox_to_page(self, bbox, page_bbox):\n",
    "        \"\"\"Ensure the bbox is safely inside the page bbox.\"\"\"\n",
    "        x0, top, x1, bottom = bbox\n",
    "        page_x0, page_top, page_x1, page_bottom = page_bbox\n",
    "\n",
    "        x0 = max(page_x0, min(x0, page_x1))\n",
    "        x1 = max(page_x0, min(x1, page_x1))\n",
    "        top = max(page_top, min(top, page_bottom))\n",
    "        bottom = max(page_top, min(bottom, page_bottom))\n",
    "\n",
    "        if x0 >= x1 or top >= bottom:\n",
    "            return None\n",
    "        return (x0, top, x1, bottom)\n",
    "\n",
    "    def _build_vision_client(self, user_type: str) -> \"vision.ImageAnnotatorClient\":\n",
    "        \"\"\"Create a Vision client based on user type.\"\"\"\n",
    "        user_type = (user_type or \"\").strip().lower()\n",
    "\n",
    "        if user_type == \"org\":\n",
    "            service_account_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "            if not service_account_path:\n",
    "                raise ValueError(\n",
    "                    \"GOOGLE_APPLICATION_CREDENTIALS is not set. Put the service account JSON path in your .env or OS env.\"\n",
    "                )\n",
    "            credentials = service_account.Credentials.from_service_account_file(service_account_path)\n",
    "            print(\"‚úÖ Organization user - using service account from GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "            return vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "        if user_type == \"byok\":\n",
    "            print(\"‚úÖ BYOK user - using Application Default Credentials for Google Vision\")\n",
    "            return vision.ImageAnnotatorClient()\n",
    "\n",
    "        raise ValueError(\"Invalid user_type. Use 'org' or 'byok'.\")\n",
    "\n",
    "    def extract_text_from_pdf(\n",
    "        self,\n",
    "        pdf_path: str,\n",
    "        user_type: str = \"org\",\n",
    "        language_hints=None,\n",
    "        out_txt: str = \"ocr_extracted_text_new.txt\",\n",
    "        keep_page_breaks: bool = True\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Extract text from PDF using text layer + selective OCR, with full-page OCR fallback.\n",
    "\n",
    "        IMPORTANT:\n",
    "        - Saves ONLY the extracted text (no '[FULL PAGE OCR]' / '[TEXT LAYER]' / page headers).\n",
    "        \"\"\"\n",
    "        client = self._build_vision_client(user_type)\n",
    "\n",
    "        all_pages_text = []\n",
    "        ocr_pages_count = 0\n",
    "\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                print(f\"\\nüìÑ Processing Page {i + 1}/{len(pdf.pages)}\")\n",
    "                parts = []\n",
    "                ocr_applied_this_page = False\n",
    "\n",
    "                # 1) Try selectable text layer\n",
    "                normal_text = (page.extract_text() or \"\").strip()\n",
    "                if normal_text and self.looks_like_cid_encoded(normal_text):\n",
    "                    print(\"‚ö†Ô∏è Detected CID-encoded garbage in text layer. Ignoring text layer.\")\n",
    "                    normal_text = \"\"\n",
    "\n",
    "                has_text_layer = bool(normal_text)\n",
    "\n",
    "                if has_text_layer:\n",
    "                    print(f\"‚úÖ Found valid text layer on page {i + 1}\")\n",
    "                    parts.append(normal_text)  # ‚úÖ no label\n",
    "\n",
    "                    # 2) OCR embedded images only (logos, stamps, scanned snippets)\n",
    "                    if page.images:\n",
    "                        print(f\"üîç Found {len(page.images)} image(s) for OCR on page {i + 1}\")\n",
    "                        ocr_applied_this_page = True\n",
    "\n",
    "                        page_bbox = (0.0, 0.0, float(page.width), float(page.height))\n",
    "                        for img_idx, img in enumerate(page.images):\n",
    "                            try:\n",
    "                                raw_bbox = (img[\"x0\"], img[\"top\"], img[\"x1\"], img[\"bottom\"])\n",
    "                                safe_bbox = self.clamp_bbox_to_page(raw_bbox, page_bbox)\n",
    "                                if not safe_bbox:\n",
    "                                    print(f\"‚ö†Ô∏è Skipping invalid bbox: {raw_bbox}\")\n",
    "                                    continue\n",
    "\n",
    "                                cropped_img = page.crop(safe_bbox).to_image(resolution=500)\n",
    "                                img_bytes = io.BytesIO()\n",
    "                                cropped_img.save(img_bytes, format=\"PNG\")\n",
    "\n",
    "                                ocr_result = self.ocr_image_bytes(\n",
    "                                    img_bytes.getvalue(), client, language_hints=language_hints\n",
    "                                ).strip()\n",
    "\n",
    "                                if ocr_result:\n",
    "                                    parts.append(ocr_result)  # ‚úÖ no label\n",
    "                            except Exception as e:\n",
    "                                print(f\"‚ö†Ô∏è Error OCR-ing image #{img_idx + 1} on page {i + 1}: {e}\")\n",
    "\n",
    "                else:\n",
    "                    # 3) If no text layer ‚Üí full-page OCR\n",
    "                    print(f\"‚ö†Ô∏è No selectable text on page {i + 1}. Performing full-page OCR.\")\n",
    "                    ocr_applied_this_page = True\n",
    "\n",
    "                    try:\n",
    "                        page_image = page.to_image(resolution=500)\n",
    "                        img_bytes = io.BytesIO()\n",
    "                        page_image.save(img_bytes, format=\"PNG\")\n",
    "\n",
    "                        full_page_ocr_result = self.ocr_image_bytes(\n",
    "                            img_bytes.getvalue(), client, language_hints=language_hints\n",
    "                        ).strip()\n",
    "\n",
    "                        if full_page_ocr_result:\n",
    "                            parts.append(full_page_ocr_result)  # ‚úÖ no label\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Error during full-page OCR on page {i + 1}: {e}\")\n",
    "\n",
    "                if ocr_applied_this_page:\n",
    "                    ocr_pages_count += 1\n",
    "\n",
    "                combined = \"\\n\\n\".join([p for p in parts if p]).strip()\n",
    "                if combined:\n",
    "                    all_pages_text.append(combined)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è No text found at all on page {i + 1}\")\n",
    "\n",
    "        print(f\"\\nüìä OCR was applied on {ocr_pages_count} out of {len(pdf.pages)} pages.\")\n",
    "\n",
    "        # ‚úÖ Save ONLY text (no PAGE headers, no OCR labels)\n",
    "        final_text = (\"\".join(all_pages_text)) if keep_page_breaks else (\"\\n\\n\".join(all_pages_text))\n",
    "        with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_text)\n",
    "\n",
    "        print(\"‚úÖ Saved to:\", out_txt)\n",
    "        return final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2c396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import io\n",
    "# import re\n",
    "# import unicodedata\n",
    "\n",
    "# import pdfplumber\n",
    "# from google.cloud import vision\n",
    "# from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# class GoogleVisionOCRProcessor:\n",
    "#     def looks_like_cid_encoded(self, text: str) -> bool:\n",
    "#         return \"(cid:\" in (text or \"\").lower()\n",
    "\n",
    "#     # ------------------- CLEANING -------------------\n",
    "#     def _alnum_ratio(self, s: str) -> float:\n",
    "#         s = s or \"\"\n",
    "#         if not s:\n",
    "#             return 0.0\n",
    "#         alnum = sum(ch.isalnum() for ch in s)\n",
    "#         return alnum / max(1, len(s))\n",
    "\n",
    "#     def _is_repeated_garbage(self, s: str) -> bool:\n",
    "#         # ggg, !!!, --- etc.\n",
    "#         s = (s or \"\").strip()\n",
    "#         return bool(re.fullmatch(r\"(.)\\1{2,}\", s)) and len(s) <= 6\n",
    "\n",
    "#     def _is_noise_line(self, line: str) -> bool:\n",
    "#         l = (line or \"\").strip()\n",
    "#         if not l:\n",
    "#             return True\n",
    "\n",
    "#         # common OCR noise from icons\n",
    "#         if l in {\"x\", \"X\", \"ggg\", \"GGG\"}:\n",
    "#             return True\n",
    "\n",
    "#         # repeated single char noise\n",
    "#         if self._is_repeated_garbage(l):\n",
    "#             return True\n",
    "\n",
    "#         # mostly symbols and very short\n",
    "#         if len(l) <= 3 and self._alnum_ratio(l) == 0:\n",
    "#             return True\n",
    "\n",
    "#         # low alnum ratio (icons / decoration) and short\n",
    "#         if self._alnum_ratio(l) < 0.20 and len(l) < 20:\n",
    "#             return True\n",
    "\n",
    "#         return False\n",
    "\n",
    "#     def _strip_weird_edge_symbols(self, line: str) -> str:\n",
    "#         # remove weird trailing symbols like „Ää or random OCR artifacts\n",
    "#         line = (line or \"\").strip()\n",
    "#         line = re.sub(r\"[^\\w\\)\\]\\}\\.,:;!?%$@#'\\\"/\\\\\\-+& ]+$\", \"\", line)\n",
    "#         return line.strip()\n",
    "\n",
    "#     def _should_join(self, prev_line: str, next_line: str) -> bool:\n",
    "#         prev_line = (prev_line or \"\").rstrip()\n",
    "#         next_line = (next_line or \"\").lstrip()\n",
    "#         if not prev_line or not next_line:\n",
    "#             return False\n",
    "\n",
    "#         # If next starts lowercase => wrapped line\n",
    "#         if next_line[0].islower():\n",
    "#             return True\n",
    "\n",
    "#         # If next starts with digit => \"tools address\" + \"5 key...\" etc.\n",
    "#         if next_line[0].isdigit():\n",
    "#             return True\n",
    "\n",
    "#         # If next begins with connectors like AND/OR/& => join\n",
    "#         if re.match(r\"^(and|or|&)\\b\", next_line, flags=re.IGNORECASE):\n",
    "#             return True\n",
    "\n",
    "#         # If prev ends with common join-words\n",
    "#         if re.search(r\"\\b(and|or|with|of|to|for|in|on|at|by)\\s*$\", prev_line, flags=re.IGNORECASE):\n",
    "#             return True\n",
    "\n",
    "#         # If prev ends with hyphen\n",
    "#         if prev_line.endswith((\"-\", \"‚Äì\")):\n",
    "#             return True\n",
    "\n",
    "#         # If next is a single word, likely continuation (e.g., \"collaboration\")\n",
    "#         if len(next_line.split()) == 1 and len(prev_line) < 60:\n",
    "#             # avoid joining brand word lines like \"Cognixia\"\n",
    "#             if next_line.strip().lower() in {\"cognixia\"}:\n",
    "#                 return False\n",
    "#             return True\n",
    "\n",
    "#         return False\n",
    "\n",
    "#     def clean_ocr_text(self, text: str) -> str:\n",
    "#         \"\"\"\n",
    "#         Cleans OCR output:\n",
    "#         - normalizes unicode\n",
    "#         - removes noise lines (ggg, X, symbol-only)\n",
    "#         - joins wrapped lines\n",
    "#         \"\"\"\n",
    "#         text = unicodedata.normalize(\"NFKC\", text or \"\")\n",
    "#         text = text.replace(\"\\x00\", \" \")\n",
    "#         text = \"\".join(ch for ch in text if ch.isprintable())\n",
    "\n",
    "#         raw_lines = [ln.strip() for ln in text.splitlines()]\n",
    "#         lines = []\n",
    "#         for ln in raw_lines:\n",
    "#             ln = self._strip_weird_edge_symbols(ln)\n",
    "#             if self._is_noise_line(ln):\n",
    "#                 continue\n",
    "#             if ln:\n",
    "#                 lines.append(ln)\n",
    "\n",
    "#         merged = []\n",
    "#         buf = \"\"\n",
    "#         for ln in lines:\n",
    "#             if not buf:\n",
    "#                 buf = ln\n",
    "#                 continue\n",
    "\n",
    "#             if self._should_join(buf, ln):\n",
    "#                 buf = f\"{buf} {ln}\"\n",
    "#             else:\n",
    "#                 merged.append(buf.strip())\n",
    "#                 buf = ln\n",
    "\n",
    "#         if buf:\n",
    "#             merged.append(buf.strip())\n",
    "\n",
    "#         # remove excessive blank lines (we removed most already)\n",
    "#         out = \"\\n\".join(merged)\n",
    "#         out = re.sub(r\"\\n{3,}\", \"\\n\\n\", out).strip()\n",
    "#         return out\n",
    "\n",
    "#     # ------------------- OCR -------------------\n",
    "#     def ocr_image_bytes(self, image_bytes: bytes, client: \"vision.ImageAnnotatorClient\", language_hints=None) -> str:\n",
    "#         if language_hints is None:\n",
    "#             language_hints = [\"en\"]\n",
    "\n",
    "#         image = vision.Image(content=image_bytes)\n",
    "#         image_context = vision.ImageContext(language_hints=language_hints)\n",
    "#         response = client.document_text_detection(image=image, image_context=image_context)\n",
    "\n",
    "#         if getattr(response, \"error\", None) and response.error.message:\n",
    "#             print(f\"‚ö†Ô∏è Google Vision OCR error: {response.error.message}\")\n",
    "#             return \"\"\n",
    "\n",
    "#         annotation = getattr(response, \"full_text_annotation\", None)\n",
    "#         if annotation and getattr(annotation, \"text\", None):\n",
    "#             return annotation.text.strip()\n",
    "#         return \"\"\n",
    "\n",
    "#     def clamp_bbox_to_page(self, bbox, page_bbox):\n",
    "#         x0, top, x1, bottom = bbox\n",
    "#         page_x0, page_top, page_x1, page_bottom = page_bbox\n",
    "\n",
    "#         x0 = max(page_x0, min(x0, page_x1))\n",
    "#         x1 = max(page_x0, min(x1, page_x1))\n",
    "#         top = max(page_top, min(top, page_bottom))\n",
    "#         bottom = max(page_top, min(bottom, page_bottom))\n",
    "\n",
    "#         if x0 >= x1 or top >= bottom:\n",
    "#             return None\n",
    "#         return (x0, top, x1, bottom)\n",
    "\n",
    "#     def _build_vision_client(self, user_type: str) -> \"vision.ImageAnnotatorClient\":\n",
    "#         user_type = (user_type or \"\").strip().lower()\n",
    "\n",
    "#         if user_type == \"org\":\n",
    "#             service_account_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "#             if not service_account_path:\n",
    "#                 raise ValueError(\"GOOGLE_APPLICATION_CREDENTIALS is not set.\")\n",
    "#             credentials = service_account.Credentials.from_service_account_file(service_account_path)\n",
    "#             print(\"‚úÖ Organization user - using service account from GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "#             return vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "#         if user_type == \"byok\":\n",
    "#             print(\"‚úÖ BYOK user - using Application Default Credentials for Google Vision\")\n",
    "#             return vision.ImageAnnotatorClient()\n",
    "\n",
    "#         raise ValueError(\"Invalid user_type. Use 'org' or 'byok'.\")\n",
    "\n",
    "#     # ------------------- PDF EXTRACT + SAVE -------------------\n",
    "#     def extract_text_from_pdf(\n",
    "#         self,\n",
    "#         pdf_path: str,\n",
    "#         user_type: str = \"org\",\n",
    "#         language_hints=None,\n",
    "#         out_txt: str = \"ocr_extracted_text.txt\",\n",
    "#         keep_page_breaks: bool = True\n",
    "#     ) -> str:\n",
    "#         client = self._build_vision_client(user_type)\n",
    "\n",
    "#         all_pages_text = []\n",
    "#         ocr_pages_count = 0\n",
    "\n",
    "#         with pdfplumber.open(pdf_path) as pdf:\n",
    "#             for i, page in enumerate(pdf.pages):\n",
    "#                 print(f\"\\nüìÑ Processing Page {i + 1}/{len(pdf.pages)}\")\n",
    "#                 parts = []\n",
    "#                 ocr_applied_this_page = False\n",
    "\n",
    "#                 # 1) Try selectable text layer\n",
    "#                 normal_text = (page.extract_text() or \"\").strip()\n",
    "#                 if normal_text and self.looks_like_cid_encoded(normal_text):\n",
    "#                     print(\"‚ö†Ô∏è Detected CID-encoded garbage in text layer. Ignoring text layer.\")\n",
    "#                     normal_text = \"\"\n",
    "\n",
    "#                 if normal_text:\n",
    "#                     # clean text layer too\n",
    "#                     normal_text = self.clean_ocr_text(normal_text)\n",
    "#                     if normal_text:\n",
    "#                         parts.append(normal_text)\n",
    "\n",
    "#                     # OCR embedded images if any\n",
    "#                     if page.images:\n",
    "#                         ocr_applied_this_page = True\n",
    "#                         page_bbox = (0.0, 0.0, float(page.width), float(page.height))\n",
    "#                         for img in page.images:\n",
    "#                             try:\n",
    "#                                 raw_bbox = (img[\"x0\"], img[\"top\"], img[\"x1\"], img[\"bottom\"])\n",
    "#                                 safe_bbox = self.clamp_bbox_to_page(raw_bbox, page_bbox)\n",
    "#                                 if not safe_bbox:\n",
    "#                                     continue\n",
    "\n",
    "#                                 cropped_img = page.crop(safe_bbox).to_image(resolution=500)\n",
    "#                                 img_bytes = io.BytesIO()\n",
    "#                                 cropped_img.save(img_bytes, format=\"PNG\")\n",
    "\n",
    "#                                 ocr_result = self.ocr_image_bytes(img_bytes.getvalue(), client, language_hints=language_hints)\n",
    "#                                 ocr_result = self.clean_ocr_text(ocr_result)\n",
    "\n",
    "#                                 if ocr_result:\n",
    "#                                     parts.append(ocr_result)\n",
    "#                             except Exception as e:\n",
    "#                                 print(f\"‚ö†Ô∏è Error OCR-ing embedded image on page {i + 1}: {e}\")\n",
    "\n",
    "#                 else:\n",
    "#                     # 2) Full-page OCR\n",
    "#                     print(f\"‚ö†Ô∏è No selectable text on page {i + 1}. Performing full-page OCR.\")\n",
    "#                     ocr_applied_this_page = True\n",
    "\n",
    "#                     try:\n",
    "#                         page_image = page.to_image(resolution=500)\n",
    "#                         img_bytes = io.BytesIO()\n",
    "#                         page_image.save(img_bytes, format=\"PNG\")\n",
    "\n",
    "#                         ocr_text = self.ocr_image_bytes(img_bytes.getvalue(), client, language_hints=language_hints)\n",
    "#                         ocr_text = self.clean_ocr_text(ocr_text)\n",
    "\n",
    "#                         if ocr_text:\n",
    "#                             parts.append(ocr_text)\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"‚ö†Ô∏è Error during full-page OCR on page {i + 1}: {e}\")\n",
    "\n",
    "#                 if ocr_applied_this_page:\n",
    "#                     ocr_pages_count += 1\n",
    "\n",
    "#                 page_text = \"\\n\\n\".join([p for p in parts if p]).strip()\n",
    "#                 if page_text:\n",
    "#                     all_pages_text.append(page_text)\n",
    "#                 else:\n",
    "#                     print(f\"‚ö†Ô∏è No text found at all on page {i + 1}\")\n",
    "\n",
    "#         print(f\"\\nüìä OCR was applied on {ocr_pages_count} out of {len(pdf.pages)} pages.\")\n",
    "\n",
    "#         final_text = (\"\\n\\n=== PAGE BREAK ===\\n\\n\".join(all_pages_text)) if keep_page_breaks else (\"\\n\\n\".join(all_pages_text))\n",
    "\n",
    "#         with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "#             f.write(final_text)\n",
    "\n",
    "#         print(\"‚úÖ Saved to:\", out_txt)\n",
    "#         return final_text\n",
    "\n",
    "\n",
    "# # ------------------- Example usage -------------------\n",
    "# # ocr = GoogleVisionOCRProcessor()\n",
    "# # text = ocr.extract_text_from_pdf(\n",
    "# #     \"/mnt/data/1-Cognixia-SecOps.pdf\",\n",
    "# #     user_type=\"org\",\n",
    "# #     language_hints=[\"en\"],\n",
    "# #     out_txt=\"secops_clean.txt\",\n",
    "# #     keep_page_breaks=True\n",
    "# # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "febd9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6fc1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "022907a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Organization user - using service account from GOOGLE_APPLICATION_CREDENTIALS\n",
      "\n",
      "üìÑ Processing Page 1/2\n",
      "‚ö†Ô∏è No selectable text on page 1. Performing full-page OCR.\n",
      "\n",
      "üìÑ Processing Page 2/2\n",
      "‚ö†Ô∏è No selectable text on page 2. Performing full-page OCR.\n",
      "\n",
      "üìä OCR was applied on 2 out of 2 pages.\n",
      "‚úÖ Saved to: ocr_extracted_text_new.txt\n",
      "‚úÖ Loaded 1 page(s) using pdfplumber + Google Vision OCR\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from langchain_core.documents import Document\n",
    "except ImportError:\n",
    "    # Older LangChain versions\n",
    "    from langchain.docstore.document import Document\n",
    "\n",
    "PDF_PATH = \"1-Cognixia-SecOps.pdf\"\n",
    "USER_TYPE = \"org\"  # 'org' (service account JSON in GOOGLE_APPLICATION_CREDENTIALS) or 'byok' (ADC)\n",
    "\n",
    "ocr = GoogleVisionOCRProcessor()\n",
    "\n",
    "try:\n",
    "    extracted_text = ocr.extract_text_from_pdf(PDF_PATH, user_type=USER_TYPE)\n",
    "\n",
    "    pages = [p.strip() for p in extracted_text.split(\"\\n\\n=== PAGE BREAK ===\\n\\n\") if p.strip()]\n",
    "    docs = [\n",
    "        Document(page_content=p, metadata={\"source\": PDF_PATH, \"page\": i + 1})\n",
    "        for i, p in enumerate(pages)\n",
    "    ]\n",
    "    print(f\"‚úÖ Loaded {len(docs)} page(s) using pdfplumber + Google Vision OCR\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è OCR pipeline failed ({e}). Falling back to PyPDFLoader text extraction.\")\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30516cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c7dd55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1032540c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00504728",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eafa6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x11621f510>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82325fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':4})\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/vishruth/Desktop/work/brandlove_poc\n",
      "PDF_PATH: 1-Cognixia-SecOps.pdf\n",
      "PDF exists: True\n",
      "docs: 1\n",
      "chunks: 1\n",
      "\n",
      "--- SAMPLE CHUNK (first 600 chars) ---\n",
      "Cognixia\n",
      "Why Organizations\n",
      "Should Implement\n",
      "SecOps?\n",
      "Goals And Benefits\n",
      "Strengthened security expertise\n",
      "Regulatory compliance\n",
      "Enhanced communication and\n",
      "collaboration\n",
      "Improved business reputation\n",
      "Continuous protection with proactive\n",
      "threat prevention\n",
      "Quick and effective incident response\n",
      "Reduced breach costs\n",
      "Enhanced resilience and credibility„Ää\n",
      "Cognixia\n",
      "Essential SecOps tools address\n",
      "5 key threat areas:\n",
      "DNS SECURITY\n",
      "ggg\n",
      "DATA\n",
      "DISCOVERY\n",
      "NETWORK DETECTION\n",
      "ANTI-PHISHING\n",
      "AND RESPONSE\n",
      "X\n",
      "PACKET-LEVEL\n",
      "VISIBILITY\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Sanity-check: did we actually load and chunk the PDF?\n",
    "import os\n",
    "print('CWD:', os.getcwd())\n",
    "print('PDF_PATH:', PDF_PATH)\n",
    "print('PDF exists:', os.path.exists(PDF_PATH))\n",
    "print('docs:', len(docs))\n",
    "print('chunks:', len(chunks))\n",
    "if chunks:\n",
    "    print('\\n--- SAMPLE CHUNK (first 600 chars) ---')\n",
    "    print(chunks[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ‚úÖ Deterministic RAG (always retrieves from the PDF before answering)\n",
    "# RESUME_SYSTEM = \"\"\"You are a strict resume evaluator.\n",
    "# You MUST answer using ONLY the provided resume context (retrieved from the PDF).\n",
    "# If the context does NOT contain the needed info, say clearly: 'Not found in the PDF.'\n",
    "\n",
    "# When asked about candidate fit for a Generative AI / LLM role or internship, provide:\n",
    "# 1) Resume summary (2-4 bullets)\n",
    "# 2) Relevant GenAI/ML strengths\n",
    "# 3) Gaps / risks\n",
    "# 4) Fit score (0-10) with 1-line justification\n",
    "# 5) Next steps / interview questions\n",
    "# \"\"\"\n",
    "\n",
    "# def resume_answer(query: str) -> str:\n",
    "#     hits = retriever.invoke(query)\n",
    "#     if not hits:\n",
    "#         return (\n",
    "#             \"I couldn't retrieve any relevant text from the PDF for this question. \"\n",
    "#             \"Check that docs/chunks are not empty and that OCR/text extraction worked.\"\n",
    "#         )\n",
    "\n",
    "#     context = \"\\n\\n\".join(\n",
    "#         [f\"[Page {d.metadata.get('page','?')}]\\n{d.page_content}\" for d in hits]\n",
    "#     )\n",
    "\n",
    "#     messages = [\n",
    "#         SystemMessage(content=RESUME_SYSTEM),\n",
    "#         HumanMessage(content=f\"Question: {query}\\n\\nResume context from PDF:\\n{context}\")\n",
    "#     ]\n",
    "#     return llm.invoke(messages).content\n",
    "\n",
    "# print(resume_answer('Based on the resume, is the candidate suitable for a Generative AI internship? Give reasoning and a score out of 10.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddf03295",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_ANALYST_SYSTEM = \"\"\"You are a strict PDF analyst.\n",
    "\n",
    "RULES (NON-NEGOTIABLE):\n",
    "- You MUST answer using ONLY the provided PDF context (retrieved text).\n",
    "- If a requested FACT is not present in the context, say exactly: 'Not found in the PDF.'\n",
    "- Do NOT use outside knowledge.\n",
    "\n",
    "IMPORTANT OUTPUT RULES:\n",
    "- Sections 1‚Äì3 must be extracted strictly from the PDF context.\n",
    "- Section 4 must be derived from the PDF context (actionable takeaways).\n",
    "- Section 5 (questions) must be GENERATED based on topics found in the PDF context.\n",
    "  - Never say 'Not found in the PDF.' for section 5 unless the PDF context is empty.\n",
    "\n",
    "When the user asks to analyze the PDF, respond in this structure:\n",
    "1) High-level summary (3-6 bullets)\n",
    "2) Key topics / modules (bullets)\n",
    "3) Important terms / definitions (only if explicitly defined; otherwise say 'Not found in the PDF.')\n",
    "4) Practical takeaways / action items (derived from context)\n",
    "5) Likely questions for assessment/interview (8-12 questions based on context)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18ef2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def rag_tool(query):\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve relevant information from the pdf document.\n",
    "    Use this tool when the user asks factual / conceptual questions\n",
    "    that might be answered from the stored documents.\n",
    "    \"\"\"\n",
    "    result = retriever.invoke(query)\n",
    "\n",
    "    context = [doc.page_content for doc in result]\n",
    "    metadata = [doc.metadata for doc in result]\n",
    "\n",
    "    return {\n",
    "        'query': query,\n",
    "        'context': context,\n",
    "        'metadata': metadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d0ecac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [rag_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "547ccba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddb8e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState):\n",
    "\n",
    "    messages = state['messages']\n",
    "\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3955aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b61744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "graph.add_node('chat_node', chat_node)\n",
    "graph.add_node('tools', tool_node)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_conditional_edges('chat_node', tools_condition)\n",
    "graph.add_edge('tools', 'chat_node')\n",
    "\n",
    "chatbot = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a63444b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x117eae990>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "298fbbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (Optional) LangGraph tool-calling demo (kept for reference)\n",
    "# # Tip: Use resume_answer() above for guaranteed retrieval.\n",
    "# result = chatbot.invoke(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             SystemMessage(content=(\n",
    "#                 \"You are evaluating the candidate using the PDF resume. \"\n",
    "#                 \"ALWAYS call rag_tool to fetch resume context before answering. \"\n",
    "#                 \"If info isn't in the PDF, say 'Not found in the PDF.'\"\n",
    "#             )),\n",
    "#             HumanMessage(content=(\n",
    "#                 \"Based on the resume in the PDF, is the candidate suitable for a Generative AI internship? \"\n",
    "#                 \"Give strengths, gaps, fit score out of 10, and 5 interview questions.\"\n",
    "#             ))\n",
    "#         ]\n",
    "#     }\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "603d57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) LangGraph tool-calling demo (kept for reference)\n",
    "result = chatbot.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            SystemMessage(content=(\n",
    "                \"You are a strict PDF analyst.\\n\"\n",
    "                \"MANDATORY: Before writing ANY answer, you MUST call rag_tool using the user's request as input.\\n\"\n",
    "                \"Then answer using ONLY the rag_tool output (no outside knowledge).\\n\"\n",
    "                \"If rag_tool output is empty or does not contain relevant text, say exactly: 'Not found in the PDF.'\\n\\n\"\n",
    "\n",
    "                \"OUTPUT RULES:\\n\"\n",
    "                \"- Sections 1‚Äì5 must be extracted/derived ONLY from rag_tool output.\\n\"\n",
    "                \"- Section 3 (tools/technologies): list ONLY explicitly named tools. \"\n",
    "                \"If none are named, say: 'No specific tool names are mentioned in the retrieved PDF context.'\\n\"\n",
    "                \"- Section 4 (definitions): list ONLY explicitly defined terms; otherwise say: 'Not found in the PDF.'\\n\"\n",
    "                \"- Section 6 (assessment questions): ALWAYS generate 10 questions based on topics found in rag_tool output. \"\n",
    "                \"Never say 'Not found in the PDF.' for section 6 unless rag_tool output is empty.\\n\\n\"\n",
    "\n",
    "                \"Return the answer in the exact numbered structure requested.\"\n",
    "            )),\n",
    "            HumanMessage(content=(\n",
    "                \"Analyze this PDF and provide:\\n\"\n",
    "                \"1) High-level summary (3-6 bullets)\\n\"\n",
    "                \"2) Key topics/modules\\n\"\n",
    "                \"3) Tools/technologies mentioned\\n\"\n",
    "                \"4) Important terms/definitions (if present)\\n\"\n",
    "                \"5) Practical takeaways/action items\\n\"\n",
    "                \"6) prompt to recreate the document\"\n",
    "            ))\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a24c452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) High-level summary:\n",
      "   - The document discusses the importance of implementing SecOps in organizations.\n",
      "   - Goals and benefits include strengthened security expertise, regulatory compliance, and improved business reputation.\n",
      "   - It emphasizes proactive threat prevention and quick incident response.\n",
      "   - Continuous protection and reduced breach costs are highlighted.\n",
      "   - Enhanced resilience and credibility are also mentioned as key outcomes.\n",
      "\n",
      "2) Key topics/modules:\n",
      "   - Importance of SecOps\n",
      "   - Goals and benefits of SecOps implementation\n",
      "   - Threat areas addressed by essential SecOps tools\n",
      "\n",
      "3) Tools/technologies mentioned:\n",
      "   - DNS security\n",
      "   - Data discovery\n",
      "   - Network detection and response\n",
      "   - Anti-phishing\n",
      "   - Packet-level visibility\n",
      "\n",
      "4) Important terms/definitions:\n",
      "   - Not found in the PDF.\n",
      "\n",
      "5) Practical takeaways/action items:\n",
      "   - Organizations should implement SecOps to enhance security expertise and regulatory compliance.\n",
      "   - Focus on proactive threat prevention and quick incident response to improve business reputation and reduce breach costs.\n",
      "   - Use essential SecOps tools to address DNS security, data discovery, network detection and response, anti-phishing, and packet-level visibility.\n",
      "\n",
      "6) Prompt to recreate the document:\n",
      "   - \"Create a document that explains the importance and benefits of implementing SecOps in organizations, detailing key threat areas and recommending essential SecOps tools for enhancing security and compliance. Include practical takeaways for continuous protection and improving business reputation.\"\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
